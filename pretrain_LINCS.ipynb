{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.utils_train import *\n",
    "from utils.utils_data import load_data_from_df, construct_loader\n",
    "\n",
    "from models.CSG2A_net import CSG2A_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in ('true', '1')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--device', type=str, default='cuda:0')\n",
    "parser.add_argument('--seed', type=int, default=42)\n",
    "parser.add_argument('--dropout', type=float, default=0.1)\n",
    "parser.add_argument('--batchsize', type=int, default=128)\n",
    "parser.add_argument('--gene_hdim', type=int, default=64)\n",
    "\n",
    "parser.add_argument('--valid_ratio', type=float, default=0.1)\n",
    "parser.add_argument('--test_ratio', type=float, default=0.1)\n",
    "\n",
    "parser.add_argument('--patience', type=int, default=20)\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "\n",
    "parser.add_argument('--data_dir', type=str, default='./data/Transcriptome_toy/')\n",
    "parser.add_argument('--mat_pretrainf', type=str, default='./ckpts/mat_pretrained_weights.pt')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'CSG2A_pretrain_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:39:49] ==================================================\n",
      "[07:39:49] start training 240131_CSG2A_pretrain_test\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(model_name)\n",
    "logger('='*50)\n",
    "logger(f'start training {logger.date}_{logger.model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:39:49] Namespace(device='cuda:0', seed=42, dropout=0.1, batchsize=128, gene_hdim=64, valid_ratio=0.1, test_ratio=0.1, patience=20, lr=0.0001, data_dir='./data/Transcriptome_toy/', mat_pretrainf='./ckpts/mat_pretrained_weights.pt')\n",
      "[07:39:49] random seed with 42\n"
     ]
    }
   ],
   "source": [
    "logger(args)\n",
    "set_seed(args.seed,logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_feat = load_data_from_df(args.data_dir+'condition_table.csv', smiles_column = 'canonical_smiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_df = pd.read_csv(args.data_dir+'condition_table.csv')\n",
    "gex_DMSO = pd.read_csv(args.data_dir+'gex_DMSO.csv')\n",
    "gex_comp = pd.read_csv(args.data_dir+'gex_comp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DDR1</th>\n",
       "      <th>PAX8</th>\n",
       "      <th>RPS5</th>\n",
       "      <th>ABCF1</th>\n",
       "      <th>SPAG7</th>\n",
       "      <th>RHOA</th>\n",
       "      <th>RNPS1</th>\n",
       "      <th>SMNDC1</th>\n",
       "      <th>ATP6V0B</th>\n",
       "      <th>RPS6</th>\n",
       "      <th>...</th>\n",
       "      <th>P4HTM</th>\n",
       "      <th>SLC27A3</th>\n",
       "      <th>TBXA2R</th>\n",
       "      <th>RTN2</th>\n",
       "      <th>GFUS</th>\n",
       "      <th>PPARD</th>\n",
       "      <th>GNA11</th>\n",
       "      <th>WDTC1</th>\n",
       "      <th>PLSCR3</th>\n",
       "      <th>NPEPL1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.659634</td>\n",
       "      <td>-0.903503</td>\n",
       "      <td>-0.580669</td>\n",
       "      <td>0.674749</td>\n",
       "      <td>-0.959752</td>\n",
       "      <td>-1.254497</td>\n",
       "      <td>1.197722</td>\n",
       "      <td>-0.388186</td>\n",
       "      <td>1.678402</td>\n",
       "      <td>-0.690094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821481</td>\n",
       "      <td>0.649951</td>\n",
       "      <td>0.466549</td>\n",
       "      <td>0.094080</td>\n",
       "      <td>0.929152</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>0.398713</td>\n",
       "      <td>-2.429915</td>\n",
       "      <td>1.230694</td>\n",
       "      <td>1.087043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.524662</td>\n",
       "      <td>-1.023540</td>\n",
       "      <td>-0.271726</td>\n",
       "      <td>1.472793</td>\n",
       "      <td>-0.208879</td>\n",
       "      <td>-0.489726</td>\n",
       "      <td>-0.756635</td>\n",
       "      <td>-0.662601</td>\n",
       "      <td>0.227877</td>\n",
       "      <td>-0.409285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156210</td>\n",
       "      <td>-0.029926</td>\n",
       "      <td>0.658519</td>\n",
       "      <td>-0.938777</td>\n",
       "      <td>-0.077835</td>\n",
       "      <td>0.050625</td>\n",
       "      <td>-0.066842</td>\n",
       "      <td>0.280632</td>\n",
       "      <td>-0.457598</td>\n",
       "      <td>0.755879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.448470</td>\n",
       "      <td>-0.727050</td>\n",
       "      <td>-0.811899</td>\n",
       "      <td>-1.164333</td>\n",
       "      <td>0.017085</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.863134</td>\n",
       "      <td>1.418147</td>\n",
       "      <td>-0.044783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625126</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>0.533003</td>\n",
       "      <td>-0.175997</td>\n",
       "      <td>0.578045</td>\n",
       "      <td>-1.149621</td>\n",
       "      <td>-0.046796</td>\n",
       "      <td>-0.525133</td>\n",
       "      <td>0.240329</td>\n",
       "      <td>-0.061210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824797</td>\n",
       "      <td>0.025431</td>\n",
       "      <td>-0.096312</td>\n",
       "      <td>-0.046504</td>\n",
       "      <td>0.210600</td>\n",
       "      <td>-0.696141</td>\n",
       "      <td>-0.530503</td>\n",
       "      <td>-0.796290</td>\n",
       "      <td>-0.361782</td>\n",
       "      <td>-0.056279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080014</td>\n",
       "      <td>-1.100904</td>\n",
       "      <td>0.277633</td>\n",
       "      <td>1.750473</td>\n",
       "      <td>-0.199547</td>\n",
       "      <td>0.378748</td>\n",
       "      <td>-0.614527</td>\n",
       "      <td>-0.424776</td>\n",
       "      <td>0.492837</td>\n",
       "      <td>1.272370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.075069</td>\n",
       "      <td>-0.155304</td>\n",
       "      <td>-1.843406</td>\n",
       "      <td>1.740102</td>\n",
       "      <td>-0.621561</td>\n",
       "      <td>-5.090036</td>\n",
       "      <td>-1.338589</td>\n",
       "      <td>1.908388</td>\n",
       "      <td>-0.400165</td>\n",
       "      <td>-0.960552</td>\n",
       "      <td>...</td>\n",
       "      <td>1.785844</td>\n",
       "      <td>3.662040</td>\n",
       "      <td>2.482540</td>\n",
       "      <td>2.262325</td>\n",
       "      <td>-2.178323</td>\n",
       "      <td>4.328634</td>\n",
       "      <td>-4.337384</td>\n",
       "      <td>-0.822997</td>\n",
       "      <td>-2.267418</td>\n",
       "      <td>4.080919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.790350</td>\n",
       "      <td>0.459250</td>\n",
       "      <td>-0.363200</td>\n",
       "      <td>1.512900</td>\n",
       "      <td>-0.743400</td>\n",
       "      <td>-0.655950</td>\n",
       "      <td>-0.466650</td>\n",
       "      <td>0.797150</td>\n",
       "      <td>-1.821450</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205750</td>\n",
       "      <td>0.708550</td>\n",
       "      <td>1.628100</td>\n",
       "      <td>1.175150</td>\n",
       "      <td>-0.758900</td>\n",
       "      <td>0.978050</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>-0.791700</td>\n",
       "      <td>-0.367250</td>\n",
       "      <td>1.837600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.721876</td>\n",
       "      <td>1.082948</td>\n",
       "      <td>0.279794</td>\n",
       "      <td>-0.595703</td>\n",
       "      <td>0.717329</td>\n",
       "      <td>0.310753</td>\n",
       "      <td>-0.230457</td>\n",
       "      <td>-0.384464</td>\n",
       "      <td>-0.199041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.676923</td>\n",
       "      <td>-0.641107</td>\n",
       "      <td>0.125286</td>\n",
       "      <td>0.570545</td>\n",
       "      <td>0.215509</td>\n",
       "      <td>1.224879</td>\n",
       "      <td>0.023165</td>\n",
       "      <td>-0.220200</td>\n",
       "      <td>-0.099255</td>\n",
       "      <td>-0.061096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.320603</td>\n",
       "      <td>0.338305</td>\n",
       "      <td>-0.079068</td>\n",
       "      <td>-0.565042</td>\n",
       "      <td>-0.218407</td>\n",
       "      <td>0.058194</td>\n",
       "      <td>0.068526</td>\n",
       "      <td>0.066677</td>\n",
       "      <td>0.642542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.581052</td>\n",
       "      <td>-0.268545</td>\n",
       "      <td>-0.499938</td>\n",
       "      <td>-0.482092</td>\n",
       "      <td>-0.021250</td>\n",
       "      <td>-0.719707</td>\n",
       "      <td>-0.191934</td>\n",
       "      <td>1.150662</td>\n",
       "      <td>-0.758694</td>\n",
       "      <td>-0.671634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.824646</td>\n",
       "      <td>0.384784</td>\n",
       "      <td>0.211290</td>\n",
       "      <td>1.098780</td>\n",
       "      <td>0.100735</td>\n",
       "      <td>1.183465</td>\n",
       "      <td>0.662965</td>\n",
       "      <td>4.527091</td>\n",
       "      <td>1.008273</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558384</td>\n",
       "      <td>-0.041820</td>\n",
       "      <td>1.988617</td>\n",
       "      <td>1.109972</td>\n",
       "      <td>-1.847901</td>\n",
       "      <td>1.202578</td>\n",
       "      <td>-1.801144</td>\n",
       "      <td>-2.210637</td>\n",
       "      <td>-1.776304</td>\n",
       "      <td>-2.893174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.816106</td>\n",
       "      <td>0.292985</td>\n",
       "      <td>1.609600</td>\n",
       "      <td>-0.882163</td>\n",
       "      <td>-1.751060</td>\n",
       "      <td>-0.509439</td>\n",
       "      <td>0.212084</td>\n",
       "      <td>1.076517</td>\n",
       "      <td>1.157153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315749</td>\n",
       "      <td>-1.636307</td>\n",
       "      <td>1.066644</td>\n",
       "      <td>-0.251035</td>\n",
       "      <td>-0.015497</td>\n",
       "      <td>-0.034838</td>\n",
       "      <td>-0.373008</td>\n",
       "      <td>0.866109</td>\n",
       "      <td>-0.198909</td>\n",
       "      <td>-1.090956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DDR1      PAX8      RPS5     ABCF1     SPAG7      RHOA     RNPS1  \\\n",
       "0    0.659634 -0.903503 -0.580669  0.674749 -0.959752 -1.254497  1.197722   \n",
       "1   -0.524662 -1.023540 -0.271726  1.472793 -0.208879 -0.489726 -0.756635   \n",
       "2   -0.448470 -0.727050 -0.811899 -1.164333  0.017085  0.001311 -0.045000   \n",
       "3    0.824797  0.025431 -0.096312 -0.046504  0.210600 -0.696141 -0.530503   \n",
       "4    2.075069 -0.155304 -1.843406  1.740102 -0.621561 -5.090036 -1.338589   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  1.790350  0.459250 -0.363200  1.512900 -0.743400 -0.655950 -0.466650   \n",
       "996 -0.721876  1.082948  0.279794 -0.595703  0.717329  0.310753 -0.230457   \n",
       "997 -0.320603  0.338305 -0.079068 -0.565042 -0.218407  0.058194  0.068526   \n",
       "998  0.824646  0.384784  0.211290  1.098780  0.100735  1.183465  0.662965   \n",
       "999 -0.816106  0.292985  1.609600 -0.882163 -1.751060 -0.509439  0.212084   \n",
       "\n",
       "       SMNDC1   ATP6V0B      RPS6  ...     P4HTM   SLC27A3    TBXA2R  \\\n",
       "0   -0.388186  1.678402 -0.690094  ...  0.821481  0.649951  0.466549   \n",
       "1   -0.662601  0.227877 -0.409285  ... -0.156210 -0.029926  0.658519   \n",
       "2    0.863134  1.418147 -0.044783  ...  0.625126  0.012461  0.533003   \n",
       "3   -0.796290 -0.361782 -0.056279  ... -0.080014 -1.100904  0.277633   \n",
       "4    1.908388 -0.400165 -0.960552  ...  1.785844  3.662040  2.482540   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.797150 -1.821450 -0.000350  ...  0.205750  0.708550  1.628100   \n",
       "996 -0.384464 -0.199041  0.000000  ... -0.676923 -0.641107  0.125286   \n",
       "997  0.066677  0.642542  0.000000  ... -0.581052 -0.268545 -0.499938   \n",
       "998  4.527091  1.008273 -0.000490  ...  0.558384 -0.041820  1.988617   \n",
       "999  1.076517  1.157153  0.000000  ...  0.315749 -1.636307  1.066644   \n",
       "\n",
       "         RTN2      GFUS     PPARD     GNA11     WDTC1    PLSCR3    NPEPL1  \n",
       "0    0.094080  0.929152  0.024015  0.398713 -2.429915  1.230694  1.087043  \n",
       "1   -0.938777 -0.077835  0.050625 -0.066842  0.280632 -0.457598  0.755879  \n",
       "2   -0.175997  0.578045 -1.149621 -0.046796 -0.525133  0.240329 -0.061210  \n",
       "3    1.750473 -0.199547  0.378748 -0.614527 -0.424776  0.492837  1.272370  \n",
       "4    2.262325 -2.178323  4.328634 -4.337384 -0.822997 -2.267418  4.080919  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  1.175150 -0.758900  0.978050 -0.022400 -0.791700 -0.367250  1.837600  \n",
       "996  0.570545  0.215509  1.224879  0.023165 -0.220200 -0.099255 -0.061096  \n",
       "997 -0.482092 -0.021250 -0.719707 -0.191934  1.150662 -0.758694 -0.671634  \n",
       "998  1.109972 -1.847901  1.202578 -1.801144 -2.210637 -1.776304 -2.893174  \n",
       "999 -0.251035 -0.015497 -0.034838 -0.373008  0.866109 -0.198909 -1.090956  \n",
       "\n",
       "[1000 rows x 978 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gex_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = construct_loader(chemical_feat, gex_DMSO.values, gex_comp.values,\n",
    "                                                           (condition_df['dose']/100).values,\n",
    "                                                           (condition_df['time']/72).values, # scale by longest time: GDSC\n",
    "                                                           batch_size = args.batchsize,\n",
    "                                                           valid_ratio = args.valid_ratio, \n",
    "                                                           test_ratio = args.test_ratio,\n",
    "                                                           seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppi adj processing\n",
    "genes = gex_DMSO.columns\n",
    "\n",
    "STRING_df = pd.read_csv(args.data_dir+'../STRING_edges.csv')\n",
    "\n",
    "STRING_df = STRING_df[(STRING_df['source'].isin(genes)) & (STRING_df['target'].isin(genes))]\n",
    "STRING_df['source_idx'] = STRING_df['source'].map(lambda x: genes.get_loc(x))\n",
    "STRING_df['target_idx'] = STRING_df['target'].map(lambda x: genes.get_loc(x))\n",
    "\n",
    "ppi_adj = torch.eye(len(genes))\n",
    "\n",
    "for pair in STRING_df[['target_idx','source_idx']].values:\n",
    "    ppi_adj[tuple(pair)] = 1\n",
    "    ppi_adj[tuple(pair[::-1])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ckpts folder\n",
    "if not os.path.exists('ckpts'):\n",
    "    os.makedirs('ckpts')\n",
    "\n",
    "modelf = f'ckpts/{logger.date}_{logger.model_name}.pt'\n",
    "early_stopper = EarlyStopper(path = modelf, printfunc = logger, patience = args.patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CSG2A_net(gex_dim = len(genes), hdim = args.gene_hdim, dropout = args.dropout, \n",
    "                  ppi_adj = ppi_adj.to(args.device), bias=False).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:39:52] Loading pretrained MAT weights: ./ckpts/mat_pretrained_weights.pt\n"
     ]
    }
   ],
   "source": [
    "if args.mat_pretrainf is not None:\n",
    "    pretrained_state_dict = torch.load(args.mat_pretrainf)\n",
    "\n",
    "    model_state_dict = model.CCE.MAT.state_dict()\n",
    "    logger(f'Loading pretrained MAT weights: {args.mat_pretrainf}')\n",
    "    for name, param in pretrained_state_dict.items():\n",
    "        if 'generator' in name:\n",
    "                continue\n",
    "        if isinstance(param, torch.nn.Parameter):\n",
    "            param = param.data\n",
    "        model_state_dict[name].copy_(param)\n",
    "else:\n",
    "    logger('No pretrained MAT weights loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:40:42] - batch1/7 of epoch1, loss: 1.3418649435043335\n",
      "[07:40:46] train_loss: 1.3619, valid_loss: 1.2475, valid_pcc: 0.0890\n",
      "[07:40:46] Validation loss decreased (inf --> 1.2475).  Saving model ...\n",
      "[07:40:50] train_loss: 1.3197, valid_loss: 1.2344, valid_pcc: 0.1199\n",
      "[07:40:50] Validation loss decreased (1.2475 --> 1.2344).  Saving model ...\n",
      "[07:41:04] train_loss: 1.3233, valid_loss: 1.2165, valid_pcc: 0.1499\n",
      "[07:41:04] Validation loss decreased (1.2344 --> 1.2165).  Saving model ...\n",
      "[07:41:19] train_loss: 1.3359, valid_loss: 1.1987, valid_pcc: 0.1751\n",
      "[07:41:19] Validation loss decreased (1.2165 --> 1.1987).  Saving model ...\n",
      "[07:41:36] train_loss: 1.2857, valid_loss: 1.1896, valid_pcc: 0.1901\n",
      "[07:41:36] Validation loss decreased (1.1987 --> 1.1896).  Saving model ...\n",
      "[07:41:50] train_loss: 1.2720, valid_loss: 1.1813, valid_pcc: 0.2033\n",
      "[07:41:50] Validation loss decreased (1.1896 --> 1.1813).  Saving model ...\n",
      "[07:42:05] train_loss: 1.2362, valid_loss: 1.1787, valid_pcc: 0.2106\n",
      "[07:42:05] Validation loss decreased (1.1813 --> 1.1787).  Saving model ...\n",
      "[07:42:09] train_loss: 1.2331, valid_loss: 1.1711, valid_pcc: 0.2211\n",
      "[07:42:09] Validation loss decreased (1.1787 --> 1.1711).  Saving model ...\n",
      "[07:42:14] train_loss: 1.2618, valid_loss: 1.1682, valid_pcc: 0.2265\n",
      "[07:42:14] Validation loss decreased (1.1711 --> 1.1682).  Saving model ...\n",
      "[07:42:30] train_loss: 1.2227, valid_loss: 1.1644, valid_pcc: 0.2325\n",
      "[07:42:30] Validation loss decreased (1.1682 --> 1.1644).  Saving model ...\n",
      "[07:42:36] train_loss: 1.2182, valid_loss: 1.1645, valid_pcc: 0.2322\n",
      "[07:42:36] EarlyStopping counter: 1/20\n",
      "[07:42:39] train_loss: 1.2111, valid_loss: 1.1658, valid_pcc: 0.2339\n",
      "[07:42:39] EarlyStopping counter: 2/20\n",
      "[07:42:43] train_loss: 1.2824, valid_loss: 1.1619, valid_pcc: 0.2362\n",
      "[07:42:43] Validation loss decreased (1.1644 --> 1.1619).  Saving model ...\n",
      "[07:42:47] train_loss: 1.2508, valid_loss: 1.1688, valid_pcc: 0.2348\n",
      "[07:42:47] EarlyStopping counter: 1/20\n",
      "[07:42:51] train_loss: 1.2164, valid_loss: 1.1647, valid_pcc: 0.2330\n",
      "[07:42:51] EarlyStopping counter: 2/20\n",
      "[07:42:55] train_loss: 1.2375, valid_loss: 1.1695, valid_pcc: 0.2329\n",
      "[07:42:55] EarlyStopping counter: 3/20\n",
      "[07:42:59] train_loss: 1.1881, valid_loss: 1.1660, valid_pcc: 0.2330\n",
      "[07:42:59] EarlyStopping counter: 4/20\n",
      "[07:43:03] train_loss: 1.1942, valid_loss: 1.1667, valid_pcc: 0.2331\n",
      "[07:43:03] EarlyStopping counter: 5/20\n",
      "[07:43:08] train_loss: 1.1809, valid_loss: 1.1679, valid_pcc: 0.2317\n",
      "[07:43:08] EarlyStopping counter: 6/20\n",
      "[07:43:12] train_loss: 1.1776, valid_loss: 1.1656, valid_pcc: 0.2345\n",
      "[07:43:12] EarlyStopping counter: 7/20\n",
      "[07:43:16] train_loss: 1.1987, valid_loss: 1.1679, valid_pcc: 0.2347\n",
      "[07:43:16] EarlyStopping counter: 8/20\n",
      "[07:43:20] train_loss: 1.2032, valid_loss: 1.1694, valid_pcc: 0.2306\n",
      "[07:43:20] EarlyStopping counter: 9/20\n",
      "[07:43:25] train_loss: 1.1724, valid_loss: 1.1781, valid_pcc: 0.2210\n",
      "[07:43:25] EarlyStopping counter: 10/20\n",
      "[07:43:29] train_loss: 1.1760, valid_loss: 1.2096, valid_pcc: 0.2141\n",
      "[07:43:29] EarlyStopping counter: 11/20\n",
      "[07:43:33] train_loss: 1.1519, valid_loss: 1.1703, valid_pcc: 0.2265\n",
      "[07:43:33] EarlyStopping counter: 12/20\n",
      "[07:43:37] train_loss: 1.1450, valid_loss: 1.2892, valid_pcc: 0.2010\n",
      "[07:43:37] EarlyStopping counter: 13/20\n",
      "[07:43:41] train_loss: 1.1639, valid_loss: 1.1653, valid_pcc: 0.2322\n",
      "[07:43:41] EarlyStopping counter: 14/20\n",
      "[07:43:44] train_loss: 1.1442, valid_loss: 1.1820, valid_pcc: 0.2244\n",
      "[07:43:44] EarlyStopping counter: 15/20\n",
      "[07:43:48] train_loss: 1.1523, valid_loss: 1.1698, valid_pcc: 0.2305\n",
      "[07:43:48] EarlyStopping counter: 16/20\n",
      "[07:43:52] train_loss: 1.1154, valid_loss: 1.1803, valid_pcc: 0.2233\n",
      "[07:43:52] EarlyStopping counter: 17/20\n",
      "[07:43:56] train_loss: 1.1087, valid_loss: 1.2086, valid_pcc: 0.2219\n",
      "[07:43:56] EarlyStopping counter: 18/20\n",
      "[07:44:01] train_loss: 1.1284, valid_loss: 1.1867, valid_pcc: 0.2251\n",
      "[07:44:01] EarlyStopping counter: 19/20\n",
      "[07:44:05] train_loss: 1.1338, valid_loss: 1.1809, valid_pcc: 0.2275\n",
      "[07:44:05] EarlyStopping counter: 20/20\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "while True:\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, epoch, args, logger)\n",
    "    valid_loss, valid_pcc = eval(model, valid_loader, criterion, args)\n",
    "    logger(f'train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}, valid_pcc: {valid_pcc:.4f}')\n",
    "    early_stopper(valid_loss, model)\n",
    "    if early_stopper.early_stop:\n",
    "        break\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:44:05] test_loss: 1.2753, test_pcc: 0.2284\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "model.load_state_dict(torch.load(modelf, map_location=args.device))\n",
    "\n",
    "test_loss, test_pcc = eval(model, test_loader, criterion, args)\n",
    "logger(f'test_loss: {test_loss:.4f}, test_pcc: {test_pcc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchdrug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
